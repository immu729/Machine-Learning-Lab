# 🧠 Machine Learning Lab Assignments

This repository contains my Machine Learning Lab work, implemented in **Python (Google Colab / scikit-learn)**.  
Each assignment folder includes Jupyter notebooks, outputs (plots), and documentation.  

---

## 📂 Repository Structure
Machine-Learning-Lab/
│── Assignment1/
│ ├── ML_Assignment1.ipynb
│ ├── outputs/ (generated plots if any)
│ └── README.md
│
│── Assignment2/
│ ├── ML_Assignment2.ipynb
│ ├── assignment_outputs/ (confusion matrices, ROC, learning curves, etc.)
│ ├── assignment_outputs.zip
│ └── README.md
│
└── README.md (this file)

---

## 📘 Assignment 1: Naive Bayes & Decision Tree

### ✨ Objectives
- Implement and evaluate **Naive Bayes Classifier**.  
- Implement and evaluate **Decision Tree Classifier**.  
- Compare their performance using accuracy, confusion matrix, and other metrics.  

### 📊 Key Highlights
- Used UCI dataset(s) (as instructed in lab).  
- Evaluated train-test splits and reported accuracy.  
- Generated confusion matrix heatmaps.  
- Compared Decision Tree depth vs accuracy.  

👉 Detailed code and outputs are in [Assignment1/](./Assignment1)  

---

## 📘 Assignment 2: Comparative Analysis of Classifiers (SVM, MLP, RF)

### ✨ Objectives
- Implement and compare:
  - **Support Vector Machines (SVM)** with Linear, Polynomial, RBF, Sigmoid kernels.  
  - **Multi-Layer Perceptron (MLP)** with tuning (momentum, epoch size, learning rate).  
  - **Random Forest Classifier** with hyperparameter tuning.  

- Evaluate models on **Wine** and **Digits** datasets.  
- Apply **PCA** for dimensionality reduction and repeat experiments.  
- Report metrics: Accuracy, Precision, Recall, F1-score, AUC.  
- Generate Confusion Matrices, ROC curves, and Learning/Loss curves.  
- Compare tuned vs non-tuned performance.  

### 📊 Key Highlights
- Train-test splits: **50:50, 60:40, 70:30, 80:20**.  
- SVM (RBF) and Random Forest achieved **>90% accuracy** after tuning.  
- PCA reduced feature dimensions while keeping accuracy stable.  
- Learning curves showed overfitting risks on small data (Wine) and stable performance on Digits.  

👉 Detailed code, outputs & plots are in [Assignment2/](./Assignment2)  

---

## 🏆 Outcomes
- Hands-on experience implementing classical ML algorithms with **scikit-learn**.  
- Learned the impact of **hyperparameter tuning** and **PCA** on model performance.  
- Built a strong base for more advanced ML projects.  

---

## 📚 References
- [Scikit-learn Documentation](https://scikit-learn.org/stable/)  
- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)  

---

## 🔗 Author
👨‍💻 **SK Naid Ahmed**  
📌 Roll No: 302311001005 | Section: A3  
